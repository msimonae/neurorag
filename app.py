import streamlit as st
import pandas as pd
import numpy as np
import networkx as nx
import itertools
import google.generativeai as genai
import chromadb
from chromadb import PersistentClient
from sentence_transformers import SentenceTransformer
from collections import Counter

# --- Configura√ß√£o da P√°gina Streamlit ---
st.set_page_config(page_title="NeuroGRAG - Copiloto Cl√≠nico", layout="wide")
st.title("üß† NeuroGRAG: Copiloto Cl√≠nico Explic√°vel")
st.markdown("""
Este aplicativo demonstra uma abordagem experimental para apoio ao racioc√≠nio m√©dico em triagem psiqui√°trica,
utilizando LLMs, grafos cl√≠nicos e Recupera√ß√£o Aumentada de Gera√ß√£o (RAG).
**Aten√ß√£o:** Este √© um projeto acad√™mico e de pesquisa. N√£o utilize para diagn√≥sticos reais.
""")

# --- Cache para Modelos e Dados ---
@st.cache_resource
def carregar_modelo_embedding():
    return SentenceTransformer('all-MiniLM-L6-v2')

@st.cache_resource
def carregar_dados_e_setup_grafo_chroma():
    try:
        df_transtornos = pd.read_csv("df_transtornos.csv")
    except FileNotFoundError:
        st.error("Arquivo 'df_transtornos.csv' n√£o encontrado. Gere-o a partir do notebook e coloque na raiz do app.")
        return None, None, None

    # 1. Grafo de Conhecimento
    G = nx.Graph()
    diagnosticos_unicos = []
    if not df_transtornos.empty:
        for _, linha in df_transtornos.iterrows():
            diag = linha['diagn√≥stico']
            if pd.notna(diag) and diag not in diagnosticos_unicos:
                 if isinstance(diag, str) and ('F' in diag or 'ND' in diag):
                    diagnosticos_unicos.append(diag)

            if pd.notna(linha['sintomas_principais']):
                sintomas = [s.strip() for s in str(linha['sintomas_principais']).split(',')]
                for sintoma in sintomas:
                    if pd.notna(diag) and pd.notna(sintoma):
                        G.add_edge(sintoma, diag, tipo='sintoma-diagnostico')

            if pd.notna(linha['tratamento']):
                tratamentos = [t.strip() for t in str(linha['tratamento']).split(',')]
                for trat in tratamentos:
                    if pd.notna(diag) and pd.notna(trat):
                        G.add_edge(diag, trat, tipo='diagn√≥stico-tratamento')
    else:
        st.warning("DataFrame df_transtornos est√° vazio. O grafo n√£o ser√° populado.")


    # 2. ChromaDB
    modelo_embed = carregar_modelo_embedding()
    chroma_client = PersistentClient(path='./chroma_saude_mental_st') # Novo path para Streamlit

    # Deletar cole√ß√£o antiga se existir para evitar conflitos de dimens√£o (opcional, mas bom para dev)
    try:
        if 'casos_clinicos_st' in [c.name for c in chroma_client.list_collections()]:
            chroma_client.delete_collection(name='casos_clinicos_st')
            st.info("Cole√ß√£o ChromaDB 'casos_clinicos_st' antiga recriada.")
    except Exception as e:
        st.warning(f"N√£o foi poss√≠vel deletar a cole√ß√£o antiga: {e}")

    colecao = chroma_client.get_or_create_collection(name='casos_clinicos_st')

    if not df_transtornos.empty and 'texto_clinico' in df_transtornos.columns:
        chunks = []
        metadados_list = []
        ids_chunks = []
        tamanho_chunk = 200 # Definido no notebook

        for idx, linha in df_transtornos.iterrows():
            texto = str(linha['texto_clinico']) # Garantir que √© string
            palavras = texto.split()
            id_paciente = str(linha['id_paciente'])
            diagnostico = str(linha['diagn√≥stico'])
            sintomas = str(linha['sintomas_principais'])

            for i_chunk in range(0, len(palavras), tamanho_chunk):
                trecho = ' '.join(palavras[i_chunk:i_chunk + tamanho_chunk])
                chunk_id = f'{id_paciente}_chunk_{i_chunk // tamanho_chunk}'
                chunks.append(trecho)
                ids_chunks.append(chunk_id)
                metadados_list.append({
                    'id_paciente': id_paciente,
                    'diagn√≥stico': diagnostico,
                    'sintomas': sintomas,
                    'indice_chunk': i_chunk // tamanho_chunk
                })

        if chunks: # Apenas se houver chunks para processar
            embeddings = modelo_embed.encode(chunks)
            colecao.add(
                embeddings=embeddings.tolist(),
                documents=chunks,
                metadatas=metadados_list,
                ids=ids_chunks
            )
            st.success(f'{len(chunks)} chunks indexados no ChromaDB.')
        else:
            st.warning("Nenhum chunk gerado para indexa√ß√£o no ChromaDB. Verifique os dados de 'texto_clinico'.")

    else:
        st.warning("Coluna 'texto_clinico' n√£o encontrada ou df_transtornos vazio. ChromaDB n√£o ser√° populado.")

    return df_transtornos, G, colecao

# --- Carregamento Inicial ---
modelo_embedding = carregar_modelo_embedding()
df_transtornos, G_conhecimento, colecao_chroma = carregar_dados_e_setup_grafo_chroma()

# --- Configura√ß√£o da API Key do Gemini ---
# Para Streamlit Cloud, use st.secrets
# Para desenvolvimento local, use st.text_input
google_api_key = st.sidebar.text_input("Cole sua GOOGLE_API_KEY do Gemini aqui:", type="password")

modelo_gemini = None
if google_api_key:
    try:
        genai.configure(api_key=google_api_key)
        modelo_gemini = genai.GenerativeModel('gemini-1.5-pro') # ou gemini-pro
        st.sidebar.success("API Key do Gemini configurada com sucesso!")
    except Exception as e:
        st.sidebar.error(f"Erro ao configurar a API Key: {e}")
else:
    st.sidebar.warning("Por favor, insira sua API Key do Gemini para continuar.")

# --- Interface do Usu√°rio ---
st.header("Entrada do Caso Cl√≠nico")
relato_paciente_input = st.text_area("Descreva o relato do paciente (sintomas, hist√≥rico, etc.):", height=150)
sintomas_chave_input = st.text_input("Informe os sintomas-chave detectados (separados por v√≠rgula):",
                                     help="Ex: tristeza profunda, fadiga, isolamento social")

if st.button("Analisar Caso Cl√≠nico") and modelo_gemini and G_conhecimento and colecao_chroma:
    if not relato_paciente_input.strip():
        st.error("Por favor, preencha o relato do paciente.")
    elif not sintomas_chave_input.strip():
        st.error("Por favor, informe os sintomas-chave.")
    else:
        with st.spinner("Analisando o caso... Este processo pode levar alguns minutos."):
            sintomas_detectados_lista = [s.strip().lower() for s in sintomas_chave_input.split(',')] # Convertido para min√∫sculas

            # 1. Consulta ao Grafo de Conhecimento
            diagnosticos_possiveis_grafo = set()
            if G_conhecimento is not None:
                for sintoma_g in sintomas_detectados_lista:
                    # Tentar encontrar o sintoma no grafo (considerando varia√ß√µes)
                    nos_candidatos = [n for n in G_conhecimento.nodes() if isinstance(n, str) and sintoma_g in n.lower()]
                    for no_candidato in nos_candidatos:
                        if G_conhecimento.has_node(no_candidato):
                            conexoes = list(G_conhecimento.neighbors(no_candidato))
                            diagnosticos_possiveis_grafo.update([d for d in conexoes if isinstance(d, str) and ('F' in d or 'ND' in d)])

            st.subheader("Resultados da An√°lise:")
            with st.expander("Diagn√≥sticos Sugeridos pelo Grafo de Conhecimento", expanded=False):
                if diagnosticos_possiveis_grafo:
                    for diag_g in diagnosticos_possiveis_grafo:
                        st.write(f"- {diag_g}")
                else:
                    st.write("Nenhum diagn√≥stico diretamente conectado aos sintomas-chave foi encontrado no grafo.")

            # 2. Consulta ao Banco Vetorial (RAG)
            rag_resultados_formatados = ["Nenhum caso semelhante encontrado no banco vetorial."]
            if colecao_chroma is not None and relato_paciente_input:
                embedding_query = modelo_embedding.encode([relato_paciente_input])
                try:
                    resultados_rag = colecao_chroma.query(
                        query_embeddings=embedding_query.tolist(),
                        n_results=3
                    )

                    docs_recuperados = []
                    if resultados_rag and resultados_rag['documents'] and resultados_rag['documents'][0]:
                        for i, doc_rag in enumerate(resultados_rag['documents'][0]):
                            meta_rag = resultados_rag['metadatas'][0][i]
                            docs_recuperados.append(
                                f"  Caso {i+1} (ID: {meta_rag.get('id_paciente', 'N/A')}, Diagn√≥stico: {meta_rag.get('diagn√≥stico', 'N/A')}):\n  Trecho: \"{doc_rag}\"\n  Sintomas Registrados: {meta_rag.get('sintomas', 'N/A')}"
                            )
                        rag_resultados_formatados = docs_recuperados

                except Exception as e:
                    st.error(f"Erro ao consultar o ChromaDB: {e}")

            with st.expander("Casos Cl√≠nicos Semelhantes (RAG)", expanded=False):
                for res_rag in rag_resultados_formatados:
                    st.markdown(res_rag)

            # 3. Gera√ß√£o da Resposta com LLM (Gemini)
            prompt_final_template = f'''
              Voc√™ √© um assistente cl√≠nico especializado em sa√∫de mental, treinado para analisar sintomas, sugerir diagn√≥sticos e indicar condutas terap√™uticas com base em conhecimento estruturado.

              Relato do Paciente:
              {relato_paciente_input}

              Sintomas-Chave Identificados:
              {', '.join(sintomas_detectados_lista)}

              Diagn√≥sticos Poss√≠veis Sugeridos pelo Grafo de Conhecimento (conex√µes diretas com sintomas-chave):
              {chr(10).join(diagnosticos_possiveis_grafo) if diagnosticos_possiveis_grafo else "Nenhum diagn√≥stico diretamente conectado encontrado no grafo."}

              Casos Cl√≠nicos Semelhantes Recuperados do Banco Vetorial (para contextualiza√ß√£o):
              {chr(10).join(rag_resultados_formatados)}

              Com base NO RELATO DO PACIENTE, nos SINTOMAS-CHAVE IDENTIFICADOS, e considerando o CONTEXTO dos diagn√≥sticos do grafo e dos casos recuperados, forne√ßa uma an√°lise cl√≠nica:

              1.  **Diagn√≥stico Mais Prov√°vel:** Indique o CID-10 e o nome do transtorno que voc√™ considera mais compat√≠vel com o relato completo do paciente.
              2.  **Justificativa Cl√≠nica:** Explique sua escolha diagn√≥stica, correlacionando os sintomas espec√≠ficos do relato do paciente com os crit√©rios diagn√≥sticos. Mencione se o hist√≥rico familiar (se houver no relato) ou outros fatores s√£o relevantes.
              3.  **Conduta Inicial Sugerida:** Recomende uma conduta terap√™utica inicial (ex: tipo de medica√ß√£o geral se aplic√°vel, tipo de psicoterapia, necessidade de acompanhamento especializado).
              4.  **Avalia√ß√£o de Risco e Encaminhamento:** Avalie brevemente se h√° indicadores de risco elevado (ex: idea√ß√£o suicida, agita√ß√£o psicomotora severa) e se um encaminhamento urgente para um psiquiatra ou servi√ßo de emerg√™ncia √© necess√°rio.

              Responda com clareza, embasamento e em linguagem cl√≠nica adequada. Foque no caso atual do paciente.
            '''

            st.info("Gerando an√°lise cl√≠nica com o modelo Gemini...")
            try:
                resposta_gemini = modelo_gemini.generate_content(prompt_final_template)
                st.subheader("An√°lise Cl√≠nica Detalhada (NeuroGRAG):")
                st.markdown(resposta_gemini.text)
            except Exception as e:
                st.error(f"Erro ao gerar resposta com o Gemini: {e}")
                st.error(f"Prompt enviado ao Gemini (para depura√ß√£o):\n```\n{prompt_final_template}\n```")

elif not modelo_gemini:
    st.info("Aguardando a inser√ß√£o da API Key do Gemini para habilitar a an√°lise.")
elif not G_conhecimento or not colecao_chroma:
    st.error("N√£o foi poss√≠vel carregar os dados do grafo ou do ChromaDB. Verifique o arquivo 'df_transtornos.csv'.")

st.sidebar.markdown("---")
st.sidebar.markdown("Desenvolvido como parte de um estudo experimental.")
st.sidebar.markdown("Aluno: Marcelo Massashi Simonae")
